{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Improvements to Week 3\n",
    "###    -DONE- Demarcating and not fitting borders\n",
    "###       Not \"done done\", in that we still lose some of Paul Abbott's data because of pandas's bizarre shift behavior.\n",
    "###    -DONE- Eliminating non 2001-8\n",
    "###    -DONE- Eliminating data loss (?)\n",
    "###       No pitchers lost to age. No games lost to unrecorded pitches/strikes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Setting up the environment.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Reading in the data.\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Part 1: Reading in performance/workload records from box score parser.\n",
    "\n",
    "allData = pd.read_csv('parse_012717afternoon.csv', \\\n",
    "                      header=None, names = ['Name', 'IP', 'H', 'H2', 'R', \\\n",
    "                                           'ER', 'BB', 'SO', 'HR', 'ERA', \\\n",
    "                                           'BF', 'Pit', 'Str', 'Ctct', 'StS', \\\n",
    "                                           'StL', 'GB', 'FB', 'LD', 'Unk', \\\n",
    "                                           'GSc', 'WPA', 'aLI', \\\n",
    "                                           'RE24', 'GameDate', 'Temperature'])\n",
    "allData = allData.drop('H2', 1)\n",
    "for c in list(allData):\n",
    "    # Get nicely formatted datetime data for each game. For pitcherFullParse, this is the 24th column.\n",
    "    if c != 'GameDate':\n",
    "        allData[c] = pd.to_numeric(allData[c], errors='ignore')\n",
    "    else:\n",
    "        allData[c] = pd.to_datetime(allData[c], format='%Y%m%d')\n",
    "# Sort by pitcher, then by date. Result is concatenated dataframes of each pitcher's career.\n",
    "allData = allData.sort_values(['Name', 'GameDate'])\n",
    "allData['interceptRow'] = np.ones(len(allData))\n",
    "# Remove dates we won't be using. Injury DB only goes from 2001-2008.\n",
    "allData = allData[allData['GameDate']>datetime.date(2001,1,1)]\n",
    "allData = allData[allData['GameDate']<datetime.date(2009,1,1)]\n",
    "# Clean out undesired columns... things we aren't using in current analysis.\n",
    "allData = allData.drop(labels=['R','HR','Ctct','StS','StL','FB','LD','Unk','GSc','WPA','aLI','RE24','Temperature'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################\n",
    "# Part 2: Read in pitcher birthdays from age_db.csv and add to performance/workload records.\n",
    "\n",
    "ageDb = pd.read_csv('db_age.csv', header=None)\n",
    "ageDb[1] = pd.to_datetime(ageDb[1], format='%Y-%m-%d', errors='coerce')\n",
    "allData['birthday'] = pd.NaT #pd.Series(np.zeros(len(allData)), index=allData.index)''\n",
    "pitcherList = allData['Name'].drop_duplicates()\n",
    "for pitcher in pitcherList:\n",
    "    if sum(ageDb[0]==pitcher) > 0:\n",
    "    ########## Age Portion    \n",
    "        age = ageDb.loc[ageDb[0]==pitcher,1].values[0]\n",
    "        pl = allData['Name']==pitcher\n",
    "        allData.loc[pl,'birthday'] = pd.Series(age, index=pl.index)\n",
    "allData['Age'] = allData['GameDate'] - allData['birthday']\n",
    "allData['Age'] = pd.to_numeric(allData['Age'].values) / 100000000000000 / 365.25\n",
    "allData = allData.drop('birthday',axis=1)\n",
    "#allData[allData.birthday.isnull()].to_csv('rejects.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################\n",
    "\n",
    "# Part 3: Calculate other pitcher-specific performance metrics.\n",
    "#    ### notational notes as statistics multiply\n",
    "#        prefices\n",
    "#        m - mean\n",
    "#        c - career total (for quotients, sum numerator over sum denominator, for other quantities, sum)\n",
    "#        f - fraction\n",
    "#        r - recent\n",
    "#        d - deviation from career average\n",
    "\n",
    "for pitcher in pitcherList:\n",
    "    pl = allData['Name']==pitcher\n",
    "    mIP = float(allData.loc[pl,'IP'].sum()) / sum(pl)\n",
    "    cERA = 9*float(allData.loc[pl,'ER'].sum()) / float(allData.loc[pl,'IP'].sum())\n",
    "    cfGB = float(allData.loc[pl,'GB'].sum()) / float(allData.loc[pl,'BF'].sum())\n",
    "    cfSO = float(allData.loc[pl,'SO'].sum()) / float(allData.loc[pl,'BF'].sum())\n",
    "    cfStr = float(allData.loc[pl,'Str'].sum()) / float(allData.loc[pl,'Pit'].sum())\n",
    "    allData.loc[pl,'mIP'] = pd.Series(mIP, index=pl.index)\n",
    "    allData.loc[pl,'cERA'] = pd.Series(cERA, index=pl.index)\n",
    "    allData.loc[pl,'cfGB'] = pd.Series(cfGB, index=pl.index)\n",
    "    allData.loc[pl,'cfSO'] = pd.Series(cfSO, index=pl.index)\n",
    "    allData.loc[pl,'cfStr'] = pd.Series(cfStr, index=pl.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38861, 19) (38861, 19) (38861,)\n"
     ]
    }
   ],
   "source": [
    "### Part 4:\n",
    "#   Set up a use matrix. This will indicate whether a row should be used in the calculation of the preceding statistics for rows below it.\n",
    "gbVar = 30 #days\n",
    "# No pitcher has pitched more than six times in the previous month.\n",
    "o1 = allData.shift(1)\n",
    "o2 = allData.shift(2)\n",
    "o3 = allData.shift(3)\n",
    "o4 = allData.shift(4)\n",
    "o5 = allData.shift(5)\n",
    "o6 = allData.shift(6)\n",
    "u1,u2,u3,u4,u5,u6 = ((allData['Name'] == o1['Name'])&((allData['GameDate']-np.timedelta64(gbVar,'D'))<o1['GameDate'])),\\\n",
    "                    ((allData['Name'] == o2['Name'])&((allData['GameDate']-np.timedelta64(gbVar,'D'))<o2['GameDate'])),\\\n",
    "                    ((allData['Name'] == o3['Name'])&((allData['GameDate']-np.timedelta64(gbVar,'D'))<o3['GameDate'])),\\\n",
    "                    ((allData['Name'] == o4['Name'])&((allData['GameDate']-np.timedelta64(gbVar,'D'))<o4['GameDate'])),\\\n",
    "                    ((allData['Name'] == o5['Name'])&((allData['GameDate']-np.timedelta64(gbVar,'D'))<o5['GameDate'])),\\\n",
    "                    ((allData['Name'] == o6['Name'])&((allData['GameDate']-np.timedelta64(gbVar,'D'))<o6['GameDate']))\n",
    "ustar = ((allData['Name']==o1['Name']))\n",
    "print allData.shape, o1.shape, u1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allData['rIP'] = allData['IP']+o1['IP']*u1.astype(int)+o2['IP']*u2.astype(int)+\\\n",
    "                               o3['IP']*u3.astype(int)+o4['IP']*u4.astype(int)+\\\n",
    "                               o5['IP']*u5.astype(int)+o6['IP']*u6.astype(int)\n",
    "allData['rBF'] = allData['BF']+o1['BF']*u1.astype(int)+o2['BF']*u2.astype(int)+\\\n",
    "                               o3['BF']*u3.astype(int)+o4['BF']*u4.astype(int)+\\\n",
    "                               o5['BF']*u5.astype(int)+o6['BF']*u6.astype(int)\n",
    "allData['rPit'] = allData['Pit']+o1['Pit']*u1.astype(int)+o2['Pit']*u2.astype(int)+\\\n",
    "                               o3['Pit']*u3.astype(int)+o4['Pit']*u4.astype(int)+\\\n",
    "                               o5['Pit']*u5.astype(int)+o6['Pit']*u6.astype(int)\n",
    "allData['rERA'] = 9*(allData['ER']+o1['ER']*u1.astype(int)+o2['ER']*u2.astype(int)+\\\n",
    "                               o3['ER']*u3.astype(int)+o4['ER']*u4.astype(int)+\\\n",
    "                               o5['ER']*u5.astype(int)+o6['ER']*u6.astype(int)) / allData['rIP']\n",
    "allData['rfGB'] = (allData['GB']+o1['GB']*u1.astype(int)+o2['GB']*u2.astype(int)+\\\n",
    "                               o3['GB']*u3.astype(int)+o4['GB']*u4.astype(int)+\\\n",
    "                               o5['GB']*u5.astype(int)+o6['GB']*u6.astype(int)) / allData['rBF']\n",
    "allData['rfSO'] = (allData['SO']+o1['SO']*u1.astype(int)+o2['SO']*u2.astype(int)+\\\n",
    "                               o3['SO']*u3.astype(int)+o4['SO']*u4.astype(int)+\\\n",
    "                               o5['SO']*u5.astype(int)+o6['SO']*u6.astype(int)) / allData['rBF']\n",
    "allData['rfStr'] = (allData['Str']+o1['Str']*u1.astype(int)+o2['Str']*u2.astype(int)+\\\n",
    "                               o3['Str']*u3.astype(int)+o4['Str']*u4.astype(int)+\\\n",
    "                               o5['Str']*u5.astype(int)+o6['Str']*u6.astype(int)) / allData['rPit']\n",
    "allData['dIP'] = allData['IP'] / allData['mIP']\n",
    "allData['drIP'] = allData['rIP'] / allData['mIP']\n",
    "allData['dERA'] = allData['ERA'] / allData['cERA']\n",
    "allData['drERA'] = allData['rERA'] / allData['cERA']\n",
    "allData['fGB'] = allData['GB'] / allData['BF']\n",
    "allData['dfGB'] = allData['fGB'] / allData['cfGB']\n",
    "allData['drfGB'] = allData['rfGB'] / allData['cfGB']\n",
    "allData['fSO'] = allData['SO'] / allData['BF']\n",
    "allData['dfSO'] = allData['fSO'] / allData['cfSO']\n",
    "allData['drfSO'] = allData['rfSO'] / allData['cfSO']\n",
    "allData['fStr'] = allData['Str'] / allData['Pit']\n",
    "allData['dfStr'] = allData['fStr'] / allData['cfStr']\n",
    "allData['drfStr'] = allData['rfStr'] / allData['cfStr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brocado01\n",
      "cordofr01\n",
      "paintla01\n",
      "charlno01\n",
      "walldo01\n",
      "hasegsh01\n",
      "myersro01\n",
      "sprinru01\n",
      "whiteri01\n",
      "fettemi01\n",
      "charlno01\n",
      "yanes01\n",
      "barcelo01\n",
      "guarded01\n",
      "silvajo01\n",
      "worreti01\n",
      "buddimi01\n",
      "daviska01\n",
      "schoupe01\n",
      "paintla01\n",
      "lincomi01\n",
      "cormirh01\n",
      "cookde01\n",
      "pichahi01\n",
      "guzmaju01\n",
      "cookde01\n",
      "brocado01\n",
      "walldo01\n",
      "santaju01\n",
      "brockch01\n",
      "rodriri02\n",
      "georgch01\n",
      "daviska01\n",
      "manzajo01\n",
      "robergr01\n",
      "wellsbo01\n",
      "riverma01\n",
      "grimsja01\n",
      "witasja01\n",
      "riverma01\n",
      "holmeda01\n",
      "embreal01\n",
      "robergr01\n",
      "riverma01\n",
      "remlimi01\n",
      "nenro01\n",
      "robergr01\n",
      "isrinja01\n",
      "witasja01\n",
      "embreal01\n",
      "fettemi01\n",
      "stantmi02\n",
      "creekdo01\n",
      "guthrma01\n",
      "holmeda01\n",
      "sprinru01\n",
      "fettemi01\n",
      "politcl01\n",
      "stantmi02\n",
      "paintla01\n",
      "smithda05\n",
      "holmeda01\n",
      "nenro01\n",
      "heredfe01\n",
      "remlimi01\n",
      "wickmbo01\n",
      "willisc01\n",
      "fordbe01\n",
      "wendetu01\n",
      "brocado01\n",
      "lincomi01\n",
      "beltrri01\n",
      "remlimi01\n",
      "hammoch01\n",
      "boehrbr01\n",
      "brocado01\n",
      "parrajo01\n",
      "servisc01\n",
      "willisc01\n",
      "rhodear01\n",
      "klinest02\n",
      "micelda01\n",
      "witasja01\n",
      "guarded01\n",
      "isrinja01\n",
      "heredfe01\n",
      "pulsibi01\n",
      "lincomi01\n",
      "ramirer02\n",
      "remlimi01\n",
      "rodrife01\n",
      "worreti01\n",
      "hawkila01\n",
      "milletr02\n",
      "foulkke01\n",
      "grimsja01\n",
      "santaju01\n",
      "rhodear01\n",
      "micelda01\n",
      "santaju01\n",
      "milletr02\n",
      "martica04\n",
      "witasja01\n",
      "dejeami01\n",
      "brocado01\n",
      "worreti01\n",
      "merckke01\n",
      "santaju01\n",
      "micelda01\n",
      "martica04\n",
      "witasja01\n",
      "foulkke01\n",
      "politcl01\n",
      "willisc01\n",
      "merckke01\n",
      "embreal01\n",
      "worreti01\n",
      "willisc01\n",
      "gordoto01\n",
      "guarded01\n",
      "merckke01\n",
      "gordoto01\n",
      "wickmbo01\n",
      "whiteri01\n",
      "willisc01\n",
      "hawkila01\n",
      "rhodear01\n",
      "guarded01\n",
      "mahayro01\n",
      "owenshe02\n",
      "gordoto01\n",
      "brocado01\n",
      "stantmi02\n",
      "owenshe02\n",
      "whiteri01\n",
      "witasja01\n",
      "bautijo01\n",
      "guarded01\n",
      "sprinru01\n",
      "isrinja01\n",
      "merckke01\n",
      "walkeja01\n",
      "gordoto01\n",
      "foulkke01\n",
      "mahayro01\n",
      "hergema01\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################################################\n",
    "\n",
    "# Part 4: Read in injury transfer dates from Disabled List transaction parser.\n",
    "\n",
    "tarData = pd.read_csv('db_dl_history.csv', header=None)\n",
    "tarData[1] = pd.to_datetime(tarData[1], format='%Y%m%d')\n",
    "allData.loc[:,'targets'] = pd.Series(np.zeros(len(allData)), index=allData.index)\n",
    "for i in range(len(tarData)):\n",
    "    dlPitch = tarData.iloc[i,0]\n",
    "    playerSubSet = allData['Name'].str.match(dlPitch,as_indexer=True)\n",
    "    if playerSubSet.sum()==0:\n",
    "        print dlPitch\n",
    "    tData = allData.loc[playerSubSet.index[playerSubSet.values],'GameDate']\n",
    "    tData2 = tData < tarData.iloc[i,1]\n",
    "    tData3 = tData2[tData2.values == True]\n",
    "    if sum(tData3) > 1:\n",
    "        allData.loc[tData3.index[-2],'targets'] = 1\n",
    "    else:\n",
    "        #print tarData.iloc[i,:]\n",
    "        e = True\n",
    "        \n",
    "#   Set up a use matrix. This will indicate whether a row should be used in the calculation of the preceding statistics for rows below it.\n",
    "gbVar = 31 #days\n",
    "# We will demand that the pitcher pitches five times in the next month. Possibly a higher bar than average, but we want clear targets.\n",
    "\n",
    "o = allData.shift(-5)\n",
    "u = (allData['Name'] == o['Name'])&((allData['GameDate']+np.timedelta64(gbVar,'D'))<o['GameDate'])\n",
    "allData.loc[u,'targets'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allData.to_csv('db_mlb_project_weekp3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print allData.loc[allData['Name']=='alvarwi01','GameDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print playerSubSet.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print u.astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
